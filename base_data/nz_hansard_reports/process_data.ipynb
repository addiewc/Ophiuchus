{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997f0adc-f534-45a3-ab68-1e93889b051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d880895-a80c-4788-913f-80f2323e2571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a3c4c6-f7c3-411c-b742-80106431fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data/november_30_2016.txt',\n",
       " 'raw_data/may_10_2017.txt',\n",
       " 'raw_data/october_19_2016.txt',\n",
       " 'raw_data/may_24_2017.txt',\n",
       " 'raw_data/march_15_2017.txt',\n",
       " 'raw_data/august_9_2017.txt',\n",
       " 'raw_data/september_21_2016.txt',\n",
       " 'raw_data/august_16_2017.txt',\n",
       " 'raw_data/august_2_2017.txt',\n",
       " 'raw_data/june_21_2017.txt',\n",
       " 'raw_data/september_14_2016.txt',\n",
       " 'raw_data/july_26_2017.txt',\n",
       " 'raw_data/november_2_2016.txt',\n",
       " 'raw_data/december_7_2016.txt',\n",
       " 'raw_data/november_9_2016.txt',\n",
       " 'raw_data/may_3_2017.txt',\n",
       " 'raw_data/april_5_2017.txt',\n",
       " 'raw_data/july_5_2017.txt',\n",
       " 'raw_data/june_28_2017.txt',\n",
       " 'raw_data/march_22_2017.txt',\n",
       " 'raw_data/june_7_2017.txt',\n",
       " 'raw_data/november_16_2016.txt',\n",
       " 'raw_data/april_12_2017.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdir = \"raw_data/\"\n",
    "general_debates = []\n",
    "for root, subroot, files in os.walk(fdir):\n",
    "    if root == fdir:\n",
    "        general_debates.extend([f\"{root}{f}\" for f in files])\n",
    "\n",
    "general_debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dce726ba-5929-487f-a48e-9e26277d1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = {\"GREEN\", \"LABOUR\", \"NATIONAL\", \"NZ FIRST\", \"OPPORTUNITIES\", \"UNITED FUTURE\", \"MĀORI\", \"ACT\"}\n",
    "\n",
    "speaker_party_mapping = {\n",
    "    \"mr speaker\": \"HOST\",\n",
    "    \"mrs speaker\": \"HOST\",\n",
    "    \"mr deputy speaker\": \"HOST\",\n",
    "    \"hon members\": \"HOST\",  # these aren't attributed to a specific person\n",
    "    \"hon member\": \"HOST\",  # same idea here\n",
    "    \"grant robertson\": \"LABOUR\",\n",
    "    \"hon david cunliffe\": \"LABOUR\",\n",
    "    \"hon paula bennett\": \"NATIONAL\",\n",
    "    \"hon anne tolley\": \"NATIONAL\",\n",
    "    \"phil twyford\": \"LABOUR\",\n",
    "    \"tracey martin\": \"NZ_FIRST\",\n",
    "    \"barbara kuriger\": \"NATIONAL\",\n",
    "    \"chris bishop\": \"NATIONAL\",\n",
    "    \"hon nikki kaye\": \"NATIONAL\",\n",
    "    \"hon alfred ngaro\": \"NATIONAL\",\n",
    "    \"louisa wall\": \"LABOUR\",\n",
    "    \"hon hekia parata\": \"NATIONAL\",\n",
    "    \"hon jo goodhew\": \"NATIONAL\",\n",
    "    \"hon trevor mallard\": \"LABOUR\",\n",
    "    \"hon louise upston\": \"NATIONAL\",\n",
    "    \"hon maggie barry\": \"NATIONAL\",\n",
    "    \"lindsay tisch\": \"NATIONAL\",\n",
    "    \"andrew little\": \"LABOUR\",\n",
    "    \"hon michael woodhouse\": \"NATIONAL\",\n",
    "    \"hon jacqui dean\": \"NATIONAL\",\n",
    "    \"rt hon winston peters\": \"NZ FIRST\",\n",
    "    \"hon ruth dyson\": \"LABOUR\",\n",
    "    \"hon nathan guy\": \"NATIONAL\",\n",
    "    \"hon david bennett\": \"NATIONAL\",\n",
    "    \"sue moroney\": \"LABOUR\",\n",
    "    \"hon scott simpson\": \"NATIONAL\",\n",
    "    \"hon bill english\": \"NATIONAL\",\n",
    "    \"bill english\": \"NATIONAL\",\n",
    "    \"rt hon bill english\": \"NATIONAL\",\n",
    "    \"clayton mitchell\": \"NZ FIRST\",\n",
    "    \"hon dr jonathan coleman\": \"NATIONAL\",\n",
    "    \"hon simon bridges\": \"NATIONAL\",\n",
    "    \"hon todd mcclay\": \"NATIONAL\",\n",
    "    \"hon amy adams\": \"NATIONAL\",\n",
    "    \"hon steven joyce\": \"NATIONAL\",\n",
    "    \"hon paul goldsmith\": \"NATIONAL\",\n",
    "    \"hon tim macindoe\": \"NATIONAL\",\n",
    "    \"hon nicky wagner\": \"NATIONAL\",\n",
    "    \"hon christopher finlayson\": \"NATIONAL\",\n",
    "    \"dr megan woods\": \"LABOUR\",\n",
    "    \"todd barclay\": \"NATIONAL\",\n",
    "    \"hon judith collins\": \"NATIONAL\",\n",
    "    \"hon craig foss\": \"NATIONAL\",\n",
    "    \"tim macindoe\": \"NATIONAL\",\n",
    "    \n",
    "}\n",
    "\n",
    "exception_set = {\n",
    "    \"here are the reasons why it all got a bit twisted\", \"the challenge for that opposition is this\", \"conservation\",\n",
    "    \"that is what this government is all about\", \"chris hipkins said\", \"let us make no mistake\", \"secondly\", \"now\",\n",
    "    \"new zealanders are saying\", \"i remember that budget for another thing\", \"the labour party is saying\",\n",
    "    \"my message is this to te ao māori\", \"there is something important i want to touch on\", \"so i want to say\",\n",
    "    \"the people of new zealand are out there saying\", \"here is another point\", \"i will read the transcript of that phone call\",\n",
    "    \"well, here is the challenge, government\", \"i want to quote from the report\", \"more on our positive vision\", \n",
    "    \"statistics new zealand said\", \"look at any metric\", \"here is some good advice\", \"let me talk about\",\n",
    "    \"i would like to ask\", \"some people ask\", \"people out there\", \"next, she says\", \"and then there is this\",\n",
    "    \"so that is what we have got\", \"the reason is\", \"i do have a little message\", \"a quick update on\",\n",
    "    \"here is a very interesting question\", \"then the other question\", \"leadership—leadership 101 says\",\n",
    "    \"i just want to say one more thing\", \"the media were asking\", \"i want to stress one thing\", \"here is what he should have said\",\n",
    "    \"here it is\", \"if we go down further\", \"here is another myth\",\n",
    "}\n",
    "\n",
    "def process_debate(debate_file):\n",
    "    with open(debate_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [l.strip() for l in lines if len(l.strip()) > 0]\n",
    "\n",
    "    statements = []  # (speaker, text -- paragraph-separated)\n",
    "    prev_speaker = None\n",
    "    running_statement = \"\"\n",
    "    for line in lines:\n",
    "        text = line\n",
    "        if \":\" in text[:50] and not any([e in line[:50].lower() for e in exception_set]):\n",
    "            if prev_speaker is not None:  ## add old information\n",
    "                statements.append((prev_speaker, running_statement.strip()))\n",
    "            \n",
    "            splits = text.split(\":\")\n",
    "            speaker = splits[0]\n",
    "            text = \":\".join(splits[1:])\n",
    "    \n",
    "            if \"(\" in speaker:\n",
    "                speaker, party_info = speaker.split(\"(\")\n",
    "                for party in parties:\n",
    "                    if party.lower() in party_info.lower():\n",
    "                        assert speaker not in speaker_party_mapping or speaker_party_mapping[speaker] == party\n",
    "                        speaker_party_mapping[speaker.lower().strip()] = party\n",
    "                if speaker.lower().strip() not in speaker_party_mapping and \"minister\" not in party_info.lower():\n",
    "                    for person in speaker_party_mapping:\n",
    "                        if person in party_info.lower().strip():  # was clarifying a person in a named position\n",
    "                            speaker = person\n",
    "                            break\n",
    "                    if speaker.lower().strip() not in speaker_party_mapping:  # still not there...\n",
    "                        print(f\"\\tMISSED ADDING PARTY FOR {speaker} and {party_info}??\")\n",
    "                        assert False\n",
    "    \n",
    "            if speaker.lower().strip() not in speaker_party_mapping:\n",
    "                print(f\"\\tMISSING PARTY INFORMATION FOR: {speaker.lower().strip()} (have {\n",
    "                    sorted(list(speaker_party_mapping.keys()))})\")\n",
    "                assert False\n",
    "            prev_speaker = speaker_party_mapping[speaker.lower().strip()]\n",
    "    \n",
    "        running_statement += f\"{text.strip()}\\n\"\n",
    "    \n",
    "    # add what we have left\n",
    "    statements.append((prev_speaker, running_statement.strip()))\n",
    "\n",
    "    return statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f7dbb094-9d81-4b91-b110-781eb64593a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...raw_data/november_30_2016.txt\n",
      "...raw_data/may_10_2017.txt\n",
      "...raw_data/october_19_2016.txt\n",
      "...raw_data/may_24_2017.txt\n",
      "...raw_data/march_15_2017.txt\n",
      "...raw_data/august_9_2017.txt\n",
      "...raw_data/september_21_2016.txt\n",
      "...raw_data/august_16_2017.txt\n",
      "...raw_data/august_2_2017.txt\n",
      "...raw_data/june_21_2017.txt\n",
      "...raw_data/september_14_2016.txt\n",
      "...raw_data/july_26_2017.txt\n",
      "...raw_data/november_2_2016.txt\n",
      "...raw_data/december_7_2016.txt\n",
      "...raw_data/november_9_2016.txt\n",
      "...raw_data/may_3_2017.txt\n",
      "...raw_data/april_5_2017.txt\n",
      "...raw_data/july_5_2017.txt\n",
      "...raw_data/june_28_2017.txt\n",
      "...raw_data/march_22_2017.txt\n",
      "...raw_data/june_7_2017.txt\n",
      "...raw_data/november_16_2016.txt\n",
      "...raw_data/april_12_2017.txt\n"
     ]
    }
   ],
   "source": [
    "debate_statements = {}\n",
    "for debate in general_debates:\n",
    "    print(f\"...{debate}\")\n",
    "    debate_statements[debate] = process_debate(debate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a7c3cd19-1bda-44ec-84e2-8802cdd63a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"processed_data/\"):\n",
    "    os.makedirs(\"processed_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "568d6f08-f7c8-4c3a-9b53-99c10e5e2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ADD_CONTEXT_TOKENS = 500\n",
    "def make_debate_dataset(statements):\n",
    "    texts = []\n",
    "    for dial_idx, dialogue in enumerate(statements):   # by the same speaker\n",
    "        speaker, statement = dialogue\n",
    "        paragraphs = statement.split(\"\\n\")\n",
    "        for p_idx, para in enumerate(paragraphs):\n",
    "            text_to_use = para\n",
    "            plen = len(para.split())\n",
    "\n",
    "            remaining_tokens = MAX_ADD_CONTEXT_TOKENS - plen\n",
    "            prev_idx = p_idx - 1\n",
    "            while remaining_tokens > 0 and prev_idx >= 0:\n",
    "                prev_para = paragraphs[prev_idx]\n",
    "                if len(prev_para.split()) <= remaining_tokens:   # add everything\n",
    "                    text_to_use = f\"{prev_para}\\n{text_to_use}\"\n",
    "                else:  # add a part\n",
    "                    text_to_use = f\"{' '.join(prev_para.split()[-remaining_tokens:])}\\n{text_to_use}\"\n",
    "                prev_idx -= 1\n",
    "                remaining_tokens -= len(prev_para.split())\n",
    "\n",
    "            # finished with this speaker...\n",
    "            text_to_use = f\"[START_{speaker}] {text_to_use} [END_{speaker}]\"\n",
    "\n",
    "            prev_dial = dial_idx - 1\n",
    "            while remaining_tokens > 0 and prev_dial >= 0:  # go to previous speakers?\n",
    "                prev_speaker, prev_dialogue = statements[prev_dial]\n",
    "                prev_paragraphs = prev_dialogue.split(\"\\n\")\n",
    "                prev_idx = len(prev_paragraphs)-1  # start with the last one!\n",
    "\n",
    "                text_to_use = f\"[END_{prev_speaker}] {text_to_use}\"  # other things will be added before this\n",
    "                while remaining_tokens > 0 and prev_idx >= 0:\n",
    "                    prev_para = prev_paragraphs[prev_idx]\n",
    "                    if len(prev_para.split()) <= remaining_tokens:   # add everything\n",
    "                        text_to_use = f\"{prev_para} {text_to_use}\"\n",
    "                    else:  # add a part\n",
    "                        text_to_use = f\"{' '.join(prev_para.split()[-remaining_tokens:])}\\n{text_to_use}\"\n",
    "                    prev_idx -= 1\n",
    "                    remaining_tokens -= len(prev_para.split())\n",
    "\n",
    "                # broke out here -- done with this previous speaker\n",
    "                text_to_use = f\"[START_{prev_speaker}] {text_to_use}\"\n",
    "                prev_dial -= 1\n",
    "\n",
    "            texts.append(text_to_use)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "494496a2-2898-4aae-b9a9-c4f18150e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...raw_data/november_30_2016.txt\n",
      "...raw_data/may_10_2017.txt\n",
      "...raw_data/october_19_2016.txt\n",
      "...raw_data/may_24_2017.txt\n",
      "...raw_data/march_15_2017.txt\n",
      "...raw_data/august_9_2017.txt\n",
      "...raw_data/september_21_2016.txt\n",
      "...raw_data/august_16_2017.txt\n",
      "...raw_data/august_2_2017.txt\n",
      "...raw_data/june_21_2017.txt\n",
      "...raw_data/september_14_2016.txt\n",
      "...raw_data/july_26_2017.txt\n",
      "...raw_data/november_2_2016.txt\n",
      "...raw_data/december_7_2016.txt\n",
      "...raw_data/november_9_2016.txt\n",
      "...raw_data/may_3_2017.txt\n",
      "...raw_data/april_5_2017.txt\n",
      "...raw_data/july_5_2017.txt\n",
      "...raw_data/june_28_2017.txt\n",
      "...raw_data/march_22_2017.txt\n",
      "...raw_data/june_7_2017.txt\n",
      "...raw_data/november_16_2016.txt\n",
      "...raw_data/april_12_2017.txt\n"
     ]
    }
   ],
   "source": [
    "for debate in debate_statements:\n",
    "    print(f\"...{debate}\")\n",
    "    texts = make_debate_dataset(statements)\n",
    "    df = pd.DataFrame.from_dict({\"text\": texts})\n",
    "    df.to_parquet(f\"processed_data/{debate.split('/')[-1].split('.txt')[0]}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a9d19-c76f-4d05-874e-e91a0fff3a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8464559-9b66-4060-8559-127f649d58da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438aeda-81b2-4b00-9617-0813a3b62a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
